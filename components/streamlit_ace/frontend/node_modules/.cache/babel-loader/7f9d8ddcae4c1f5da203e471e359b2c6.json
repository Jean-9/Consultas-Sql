{"ast":null,"code":"ace.define(\"ace/mode/json_highlight_rules\", [\"require\", \"exports\", \"module\", \"ace/lib/oop\", \"ace/mode/text_highlight_rules\"], function (require, exports, module) {\n  \"use strict\";\n\n  var oop = require(\"../lib/oop\");\n  var TextHighlightRules = require(\"./text_highlight_rules\").TextHighlightRules;\n  var JsonHighlightRules = function () {\n    this.$rules = {\n      \"start\": [{\n        token: \"variable\",\n        // single line\n        regex: '[\"](?:(?:\\\\\\\\.)|(?:[^\"\\\\\\\\]))*?[\"]\\\\s*(?=:)'\n      }, {\n        token: \"string\",\n        // single line\n        regex: '\"',\n        next: \"string\"\n      }, {\n        token: \"constant.numeric\",\n        // hex\n        regex: \"0[xX][0-9a-fA-F]+\\\\b\"\n      }, {\n        token: \"constant.numeric\",\n        // float\n        regex: \"[+-]?\\\\d+(?:(?:\\\\.\\\\d*)?(?:[eE][+-]?\\\\d+)?)?\\\\b\"\n      }, {\n        token: \"constant.language.boolean\",\n        regex: \"(?:true|false)\\\\b\"\n      }, {\n        token: \"text\",\n        // single quoted strings are not allowed\n        regex: \"['](?:(?:\\\\\\\\.)|(?:[^'\\\\\\\\]))*?[']\"\n      }, {\n        token: \"comment\",\n        // comments are not allowed, but who cares?\n        regex: \"\\\\/\\\\/.*$\"\n      }, {\n        token: \"comment.start\",\n        // comments are not allowed, but who cares?\n        regex: \"\\\\/\\\\*\",\n        next: \"comment\"\n      }, {\n        token: \"paren.lparen\",\n        regex: \"[[({]\"\n      }, {\n        token: \"paren.rparen\",\n        regex: \"[\\\\])}]\"\n      }, {\n        token: \"punctuation.operator\",\n        regex: /[,]/\n      }, {\n        token: \"text\",\n        regex: \"\\\\s+\"\n      }],\n      \"string\": [{\n        token: \"constant.language.escape\",\n        regex: /\\\\(?:x[0-9a-fA-F]{2}|u[0-9a-fA-F]{4}|[\"\\\\\\/bfnrt])/\n      }, {\n        token: \"string\",\n        regex: '\"|$',\n        next: \"start\"\n      }, {\n        defaultToken: \"string\"\n      }],\n      \"comment\": [{\n        token: \"comment.end\",\n        // comments are not allowed, but who cares?\n        regex: \"\\\\*\\\\/\",\n        next: \"start\"\n      }, {\n        defaultToken: \"comment\"\n      }]\n    };\n  };\n  oop.inherits(JsonHighlightRules, TextHighlightRules);\n  exports.JsonHighlightRules = JsonHighlightRules;\n});\nace.define(\"ace/ext/simple_tokenizer\", [\"require\", \"exports\", \"module\", \"ace/ext/simple_tokenizer\", \"ace/mode/json_highlight_rules\", \"ace/tokenizer\", \"ace/layer/text_util\"], function (require, exports, module) {\n  /**\n  * ## Simple tokenizer extension\n  *\n  * Provides standalone tokenization functionality that can parse code content using Ace's highlight rules without\n  * requiring a full editor instance. This is useful for generating syntax-highlighted tokens for external rendering,\n  * static code generation, or testing tokenization rules. The tokenizer processes text line by line and returns\n  * structured token data with CSS class names compatible with Ace themes.\n  *\n  * **Usage:**\n  * ```javascript\n  * const { tokenize } = require(\"ace/ext/simple_tokenizer\");\n  * const { JsonHighlightRules } = require(\"ace/mode/json_highlight_rules\");\n  *\n  * const content = '{\"name\": \"value\"}';\n  * const tokens = tokenize(content, new JsonHighlightRules());\n  * // Returns: [[{className: \"ace_paren ace_lparen\", value: \"{\"}, ...]]\n  * ```\n  *\n  * @module\n  */\n  \"use strict\";\n\n  var Tokenizer = require(\"../tokenizer\").Tokenizer;\n  var isTextToken = require(\"../layer/text_util\").isTextToken;\n  var SimpleTokenizer = /** @class */function () {\n    function SimpleTokenizer(content, tokenizer) {\n      this._lines = content.split(/\\r\\n|\\r|\\n/);\n      this._states = [];\n      this._tokenizer = tokenizer;\n    }\n    SimpleTokenizer.prototype.getTokens = function (row) {\n      var line = this._lines[row];\n      var previousState = this._states[row - 1];\n      var data = this._tokenizer.getLineTokens(line, previousState);\n      this._states[row] = data.state;\n      return data.tokens;\n    };\n    SimpleTokenizer.prototype.getLength = function () {\n      return this._lines.length;\n    };\n    return SimpleTokenizer;\n  }();\n  function tokenize(content, highlightRules) {\n    var tokenizer = new SimpleTokenizer(content, new Tokenizer(highlightRules.getRules()));\n    var result = [];\n    for (var lineIndex = 0; lineIndex < tokenizer.getLength(); lineIndex++) {\n      var lineTokens = tokenizer.getTokens(lineIndex);\n      result.push(lineTokens.map(function (token) {\n        return {\n          className: isTextToken(token.type) ? undefined : \"ace_\" + token.type.replace(/\\./g, \" ace_\"),\n          value: token.value\n        };\n      }));\n    }\n    return result;\n  }\n  exports.tokenize = tokenize;\n});\n(function () {\n  ace.require([\"ace/ext/simple_tokenizer\"], function (m) {\n    if (typeof module == \"object\" && typeof exports == \"object\" && module) {\n      module.exports = m;\n    }\n  });\n})();","map":{"version":3,"names":["ace","define","require","exports","module","oop","TextHighlightRules","JsonHighlightRules","$rules","token","regex","next","defaultToken","inherits","Tokenizer","isTextToken","SimpleTokenizer","content","tokenizer","_lines","split","_states","_tokenizer","prototype","getTokens","row","line","previousState","data","getLineTokens","state","tokens","getLength","length","tokenize","highlightRules","getRules","result","lineIndex","lineTokens","push","map","className","type","undefined","replace","value","m"],"sources":["C:/Users/jean9/Desktop/projeto_rm/components/streamlit_ace/frontend/node_modules/ace-builds/src-noconflict/ext-simple_tokenizer.js"],"sourcesContent":["ace.define(\"ace/mode/json_highlight_rules\",[\"require\",\"exports\",\"module\",\"ace/lib/oop\",\"ace/mode/text_highlight_rules\"], function(require, exports, module){\"use strict\";\nvar oop = require(\"../lib/oop\");\nvar TextHighlightRules = require(\"./text_highlight_rules\").TextHighlightRules;\nvar JsonHighlightRules = function () {\n    this.$rules = {\n        \"start\": [\n            {\n                token: \"variable\", // single line\n                regex: '[\"](?:(?:\\\\\\\\.)|(?:[^\"\\\\\\\\]))*?[\"]\\\\s*(?=:)'\n            }, {\n                token: \"string\", // single line\n                regex: '\"',\n                next: \"string\"\n            }, {\n                token: \"constant.numeric\", // hex\n                regex: \"0[xX][0-9a-fA-F]+\\\\b\"\n            }, {\n                token: \"constant.numeric\", // float\n                regex: \"[+-]?\\\\d+(?:(?:\\\\.\\\\d*)?(?:[eE][+-]?\\\\d+)?)?\\\\b\"\n            }, {\n                token: \"constant.language.boolean\",\n                regex: \"(?:true|false)\\\\b\"\n            }, {\n                token: \"text\", // single quoted strings are not allowed\n                regex: \"['](?:(?:\\\\\\\\.)|(?:[^'\\\\\\\\]))*?[']\"\n            }, {\n                token: \"comment\", // comments are not allowed, but who cares?\n                regex: \"\\\\/\\\\/.*$\"\n            }, {\n                token: \"comment.start\", // comments are not allowed, but who cares?\n                regex: \"\\\\/\\\\*\",\n                next: \"comment\"\n            }, {\n                token: \"paren.lparen\",\n                regex: \"[[({]\"\n            }, {\n                token: \"paren.rparen\",\n                regex: \"[\\\\])}]\"\n            }, {\n                token: \"punctuation.operator\",\n                regex: /[,]/\n            }, {\n                token: \"text\",\n                regex: \"\\\\s+\"\n            }\n        ],\n        \"string\": [\n            {\n                token: \"constant.language.escape\",\n                regex: /\\\\(?:x[0-9a-fA-F]{2}|u[0-9a-fA-F]{4}|[\"\\\\\\/bfnrt])/\n            }, {\n                token: \"string\",\n                regex: '\"|$',\n                next: \"start\"\n            }, {\n                defaultToken: \"string\"\n            }\n        ],\n        \"comment\": [\n            {\n                token: \"comment.end\", // comments are not allowed, but who cares?\n                regex: \"\\\\*\\\\/\",\n                next: \"start\"\n            }, {\n                defaultToken: \"comment\"\n            }\n        ]\n    };\n};\noop.inherits(JsonHighlightRules, TextHighlightRules);\nexports.JsonHighlightRules = JsonHighlightRules;\n\n});\n\nace.define(\"ace/ext/simple_tokenizer\",[\"require\",\"exports\",\"module\",\"ace/ext/simple_tokenizer\",\"ace/mode/json_highlight_rules\",\"ace/tokenizer\",\"ace/layer/text_util\"], function(require, exports, module){/**\n * ## Simple tokenizer extension\n *\n * Provides standalone tokenization functionality that can parse code content using Ace's highlight rules without\n * requiring a full editor instance. This is useful for generating syntax-highlighted tokens for external rendering,\n * static code generation, or testing tokenization rules. The tokenizer processes text line by line and returns\n * structured token data with CSS class names compatible with Ace themes.\n *\n * **Usage:**\n * ```javascript\n * const { tokenize } = require(\"ace/ext/simple_tokenizer\");\n * const { JsonHighlightRules } = require(\"ace/mode/json_highlight_rules\");\n *\n * const content = '{\"name\": \"value\"}';\n * const tokens = tokenize(content, new JsonHighlightRules());\n * // Returns: [[{className: \"ace_paren ace_lparen\", value: \"{\"}, ...]]\n * ```\n *\n * @module\n */\n\"use strict\";\nvar Tokenizer = require(\"../tokenizer\").Tokenizer;\nvar isTextToken = require(\"../layer/text_util\").isTextToken;\nvar SimpleTokenizer = /** @class */ (function () {\n    function SimpleTokenizer(content, tokenizer) {\n        this._lines = content.split(/\\r\\n|\\r|\\n/);\n        this._states = [];\n        this._tokenizer = tokenizer;\n    }\n    SimpleTokenizer.prototype.getTokens = function (row) {\n        var line = this._lines[row];\n        var previousState = this._states[row - 1];\n        var data = this._tokenizer.getLineTokens(line, previousState);\n        this._states[row] = data.state;\n        return data.tokens;\n    };\n    SimpleTokenizer.prototype.getLength = function () {\n        return this._lines.length;\n    };\n    return SimpleTokenizer;\n}());\nfunction tokenize(content, highlightRules) {\n    var tokenizer = new SimpleTokenizer(content, new Tokenizer(highlightRules.getRules()));\n    var result = [];\n    for (var lineIndex = 0; lineIndex < tokenizer.getLength(); lineIndex++) {\n        var lineTokens = tokenizer.getTokens(lineIndex);\n        result.push(lineTokens.map(function (token) { return ({\n            className: isTextToken(token.type) ? undefined : \"ace_\" + token.type.replace(/\\./g, \" ace_\"),\n            value: token.value\n        }); }));\n    }\n    return result;\n}\nexports.tokenize = tokenize;\n\n});                (function() {\n                    ace.require([\"ace/ext/simple_tokenizer\"], function(m) {\n                        if (typeof module == \"object\" && typeof exports == \"object\" && module) {\n                            module.exports = m;\n                        }\n                    });\n                })();\n            "],"mappings":"AAAAA,GAAG,CAACC,MAAM,CAAC,+BAA+B,EAAC,CAAC,SAAS,EAAC,SAAS,EAAC,QAAQ,EAAC,aAAa,EAAC,+BAA+B,CAAC,EAAE,UAASC,OAAO,EAAEC,OAAO,EAAEC,MAAM,EAAC;EAAC,YAAY;;EACxK,IAAIC,GAAG,GAAGH,OAAO,CAAC,YAAY,CAAC;EAC/B,IAAII,kBAAkB,GAAGJ,OAAO,CAAC,wBAAwB,CAAC,CAACI,kBAAkB;EAC7E,IAAIC,kBAAkB,GAAG,SAAAA,CAAA,EAAY;IACjC,IAAI,CAACC,MAAM,GAAG;MACV,OAAO,EAAE,CACL;QACIC,KAAK,EAAE,UAAU;QAAE;QACnBC,KAAK,EAAE;MACX,CAAC,EAAE;QACCD,KAAK,EAAE,QAAQ;QAAE;QACjBC,KAAK,EAAE,GAAG;QACVC,IAAI,EAAE;MACV,CAAC,EAAE;QACCF,KAAK,EAAE,kBAAkB;QAAE;QAC3BC,KAAK,EAAE;MACX,CAAC,EAAE;QACCD,KAAK,EAAE,kBAAkB;QAAE;QAC3BC,KAAK,EAAE;MACX,CAAC,EAAE;QACCD,KAAK,EAAE,2BAA2B;QAClCC,KAAK,EAAE;MACX,CAAC,EAAE;QACCD,KAAK,EAAE,MAAM;QAAE;QACfC,KAAK,EAAE;MACX,CAAC,EAAE;QACCD,KAAK,EAAE,SAAS;QAAE;QAClBC,KAAK,EAAE;MACX,CAAC,EAAE;QACCD,KAAK,EAAE,eAAe;QAAE;QACxBC,KAAK,EAAE,QAAQ;QACfC,IAAI,EAAE;MACV,CAAC,EAAE;QACCF,KAAK,EAAE,cAAc;QACrBC,KAAK,EAAE;MACX,CAAC,EAAE;QACCD,KAAK,EAAE,cAAc;QACrBC,KAAK,EAAE;MACX,CAAC,EAAE;QACCD,KAAK,EAAE,sBAAsB;QAC7BC,KAAK,EAAE;MACX,CAAC,EAAE;QACCD,KAAK,EAAE,MAAM;QACbC,KAAK,EAAE;MACX,CAAC,CACJ;MACD,QAAQ,EAAE,CACN;QACID,KAAK,EAAE,0BAA0B;QACjCC,KAAK,EAAE;MACX,CAAC,EAAE;QACCD,KAAK,EAAE,QAAQ;QACfC,KAAK,EAAE,KAAK;QACZC,IAAI,EAAE;MACV,CAAC,EAAE;QACCC,YAAY,EAAE;MAClB,CAAC,CACJ;MACD,SAAS,EAAE,CACP;QACIH,KAAK,EAAE,aAAa;QAAE;QACtBC,KAAK,EAAE,QAAQ;QACfC,IAAI,EAAE;MACV,CAAC,EAAE;QACCC,YAAY,EAAE;MAClB,CAAC;IAET,CAAC;EACL,CAAC;EACDP,GAAG,CAACQ,QAAQ,CAACN,kBAAkB,EAAED,kBAAkB,CAAC;EACpDH,OAAO,CAACI,kBAAkB,GAAGA,kBAAkB;AAE/C,CAAC,CAAC;AAEFP,GAAG,CAACC,MAAM,CAAC,0BAA0B,EAAC,CAAC,SAAS,EAAC,SAAS,EAAC,QAAQ,EAAC,0BAA0B,EAAC,+BAA+B,EAAC,eAAe,EAAC,qBAAqB,CAAC,EAAE,UAASC,OAAO,EAAEC,OAAO,EAAEC,MAAM,EAAC;EAAC;AAC1M;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACA,YAAY;;EACZ,IAAIU,SAAS,GAAGZ,OAAO,CAAC,cAAc,CAAC,CAACY,SAAS;EACjD,IAAIC,WAAW,GAAGb,OAAO,CAAC,oBAAoB,CAAC,CAACa,WAAW;EAC3D,IAAIC,eAAe,GAAG,aAAe,YAAY;IAC7C,SAASA,eAAeA,CAACC,OAAO,EAAEC,SAAS,EAAE;MACzC,IAAI,CAACC,MAAM,GAAGF,OAAO,CAACG,KAAK,CAAC,YAAY,CAAC;MACzC,IAAI,CAACC,OAAO,GAAG,EAAE;MACjB,IAAI,CAACC,UAAU,GAAGJ,SAAS;IAC/B;IACAF,eAAe,CAACO,SAAS,CAACC,SAAS,GAAG,UAAUC,GAAG,EAAE;MACjD,IAAIC,IAAI,GAAG,IAAI,CAACP,MAAM,CAACM,GAAG,CAAC;MAC3B,IAAIE,aAAa,GAAG,IAAI,CAACN,OAAO,CAACI,GAAG,GAAG,CAAC,CAAC;MACzC,IAAIG,IAAI,GAAG,IAAI,CAACN,UAAU,CAACO,aAAa,CAACH,IAAI,EAAEC,aAAa,CAAC;MAC7D,IAAI,CAACN,OAAO,CAACI,GAAG,CAAC,GAAGG,IAAI,CAACE,KAAK;MAC9B,OAAOF,IAAI,CAACG,MAAM;IACtB,CAAC;IACDf,eAAe,CAACO,SAAS,CAACS,SAAS,GAAG,YAAY;MAC9C,OAAO,IAAI,CAACb,MAAM,CAACc,MAAM;IAC7B,CAAC;IACD,OAAOjB,eAAe;EAC1B,CAAC,CAAC,CAAE;EACJ,SAASkB,QAAQA,CAACjB,OAAO,EAAEkB,cAAc,EAAE;IACvC,IAAIjB,SAAS,GAAG,IAAIF,eAAe,CAACC,OAAO,EAAE,IAAIH,SAAS,CAACqB,cAAc,CAACC,QAAQ,CAAC,CAAC,CAAC,CAAC;IACtF,IAAIC,MAAM,GAAG,EAAE;IACf,KAAK,IAAIC,SAAS,GAAG,CAAC,EAAEA,SAAS,GAAGpB,SAAS,CAACc,SAAS,CAAC,CAAC,EAAEM,SAAS,EAAE,EAAE;MACpE,IAAIC,UAAU,GAAGrB,SAAS,CAACM,SAAS,CAACc,SAAS,CAAC;MAC/CD,MAAM,CAACG,IAAI,CAACD,UAAU,CAACE,GAAG,CAAC,UAAUhC,KAAK,EAAE;QAAE,OAAQ;UAClDiC,SAAS,EAAE3B,WAAW,CAACN,KAAK,CAACkC,IAAI,CAAC,GAAGC,SAAS,GAAG,MAAM,GAAGnC,KAAK,CAACkC,IAAI,CAACE,OAAO,CAAC,KAAK,EAAE,OAAO,CAAC;UAC5FC,KAAK,EAAErC,KAAK,CAACqC;QACjB,CAAC;MAAG,CAAC,CAAC,CAAC;IACX;IACA,OAAOT,MAAM;EACjB;EACAlC,OAAO,CAAC+B,QAAQ,GAAGA,QAAQ;AAE3B,CAAC,CAAC;AAAiB,CAAC,YAAW;EACXlC,GAAG,CAACE,OAAO,CAAC,CAAC,0BAA0B,CAAC,EAAE,UAAS6C,CAAC,EAAE;IAClD,IAAI,OAAO3C,MAAM,IAAI,QAAQ,IAAI,OAAOD,OAAO,IAAI,QAAQ,IAAIC,MAAM,EAAE;MACnEA,MAAM,CAACD,OAAO,GAAG4C,CAAC;IACtB;EACJ,CAAC,CAAC;AACN,CAAC,EAAE,CAAC","ignoreList":[]},"metadata":{},"sourceType":"script"}